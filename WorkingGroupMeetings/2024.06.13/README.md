# 2024.06.13 Meeting Summary - DeAI Working Group for the Internet Computer (ICP)

## Short Version
In today's call of the DeAI Working Group for the Internet Computer, several key initiatives were discussed. The team plans to develop a survey to gather information from ecosystem teams building AI projects, aiming to create a tailored marketing strategy. The importance of tracking usage statistics for decentralized AI applications was emphasized to demonstrate activity and traction to potential partners. Updates were provided on the scheduling of DeAI live streams and organizing a DeAI panel for the Chain Fusion Day event at EthCC. A proposal to draft a decentralized AI manifesto was made to outline principles and goals. The group considered creating a chart to rate projects on their actual use of AI technology, enhancing transparency. Jessie presented a draft outline for new documentation pages to improve decentralized AI documentation. Metrics for tracking developer engagement were discussed. Giles shared his challenges in fine-tuning a large language model (LLM) on the Internet Computer, highlighting the approach of dividing the model into smaller segments. Technical issues like efficient data loading across canisters and handling large data files were discussed, with suggestions to use separate endpoints to load weights. The discussion emphasized the importance of data privacy in AI applications and the potential of the Internet Computer in collaborative AI development. It was noted that specialized tasks might not require extremely large models, with more compact models being sufficient for many use cases. The group touched on current capabilities of the IC in running LLMs and the need for efficiency improvements. Discussions included optimizing Rust code using SIMD, creating a reusable library in Rust, and managing large models by splitting them into canisters. The challenges and potential of utilizing GPUs for AI on the Internet Computer were briefly discussed. The call concluded with a reminder of the upcoming scalability and performance working group meeting, encouraging participants to share topics and initiatives for future sessions.

## Long Version
In today's call of the DeAI Working Group for the Internet Computer, the discussion focused on several key initiatives:
- Survey Development: The team discussed creating a survey to gather information from ecosystem teams building AI projects. The aim is to understand their successes, comfort levels with promotion methods, and preferences for live streams or documentation. The survey will help create a tailored marketing strategy to highlight success stories and will be reviewed internally before distribution.
- Statistics and Usage Tracking: The importance of collecting usage statistics for decentralized AI applications was emphasized. This data is vital for demonstrating activity and traction to potential partners like CoinMarketCap. The group considered separating the efforts to track developer engagement and usage statistics from those of marketing strategies.
- DeAI Live Streams: Updates were provided on the scheduling of DeAI live streams, which will feature different teams and their projects. This initiative aims to enhance visibility and engagement within the community.
- EthCC Event: The group is organizing a DeAI panel for the Chain Fusion Day event at EthCC. Members attending the event were encouraged to reach out for participation.
- Decentralized AI Manifesto: There was a proposal to draft a decentralized AI manifesto as a joint effort from the group. The draft will be created and shared for contributions from all members, aiming to outline the principles and goals of decentralized AI.
- Technical Analysis of AI Projects: An idea was proposed to create a chart rating projects on their actual use of AI technology, ranging from full implementation to minimal involvement. This would help in setting realistic expectations and enhancing transparency.
- Documentation Enhancement: Jessie presented a draft outline for new documentation pages to fill gaps in the current decentralized AI documentation. Feedback was sought on both the general layout and specific content suggestions to improve the documentation: https://docs.google.com/document/d/1tf6kbzE2Vqxb5I6JUWZzJJpQ0qmGXkOfNqcU4yBWOSQ/edit 
- Metrics for Developer Engagement: The group discussed tracking metrics such as the number of developers attending meetings, using dev tools, and engaging with AI-specific features. These metrics will help gauge interest and activity in the AI space within the Internet Computer ecosystem.
- LLM Implementation Challenges: Giles shared his experiences and challenges in trying to fine-tune a large language model (LLM) on the Internet Computer (IC). Despite initial aspirations, he acknowledged the limitations posed by data and instruction constraints. He highlighted their approach of dividing the model into smaller segments, using canisters to manage different layers of the model.
- Technical Issues and Solutions: The speaker discussed encountering technical roadblocks, such as loading data efficiently across canisters and handling large data files. They suggested using separate endpoints to load weights into the canisters, given the 100 MB limit per canister.
- Data Privacy and IC Advantages: The discussion emphasized the importance of data privacy in AI applications. The speaker argued that the Internet Computer could play a significant role due to its privacy features and the potential to pool data securely within groups for collaborative AI development.
- Specialized Use Cases: There was a consensus that specialized tasks might not require extremely large models like GPT-3 or GPT-4. Instead, more compact models, such as LLaMA3 with 8 billion parameters, could be sufficient for many use cases, especially when fine-tuned for specific tasks.
- Model Performance on IC: The group touched on the current capabilities of the IC in running LLMs. They mentioned previous successes with smaller models and the need to further explore efficiency improvements, such as leveraging SIMD (Single Instruction, Multiple Data) optimizations and exploring quantization techniques to reduce model size and computational demands.
- Future Directions and Collaboration: The section concluded with discussions on future directions, including breaking down models into canisters, exploring federated learning on the IC, and ensuring that the community can share and build upon each other's work.
- Rust and SIMD Optimization: The conversation continued on optimizing Rust code using SIMD (Single Instruction, Multiple Data). There was also mention of float optimization on the mainnet, leading to significant performance improvements (https://github.com/dfinity/examples/pull/887, https://github.com/sonos/tract/pull/1420).
- Library and Code Reusability: Participants discussed the possibility of creating a reusable library in Rust that would facilitate AI development on the Internet Computer, similar to what is available in Python with libraries like PyTorch. This would help standardize and streamline AI projects.
- Handling Large Models: A method to manage large language models (LLMs) was discussed, involving splitting the model into multiple canisters, each handling different layers. There was a focus on efficiently handling the computational load and data transfer between canisters.
- Cross-Canister Calls: A solution was proposed to handle instruction limits by using cross-canister calls within the same canister, allowing for more extensive computations without hitting instruction limits.
- GPU Utilization: There was a brief discussion on the challenges and potential of utilizing GPUs for AI on the Internet Computer. It was noted that while GPUs can offer significant performance benefits, there are substantial challenges in ensuring deterministic computation and managing errors in a decentralized environment.
- Future Meetings and Collaboration: The call ended with a reminder of the upcoming scalability and performance working group meeting, which would be relevant to the DeAI group. Participants were encouraged to share topics and initiatives for future sessions and to continue collaborating on technical issues.

